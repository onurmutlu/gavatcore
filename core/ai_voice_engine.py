#!/usr/bin/env python3
"""
GavatCore V2 - AI Voice Engine
GPT-4o + Whisper + TTS entegrasyonu ile ger√ßek zamanlƒ± sesli etkile≈üim
"""

import asyncio
import json
import time
import uuid
import tempfile
import os
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
import structlog
import openai
import aiofiles

# Geli≈ümi≈ü config import
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config import (
    OPENAI_API_KEY, OPENAI_MODEL, OPENAI_TTS_MODEL, OPENAI_TTS_VOICE, OPENAI_STT_MODEL,
    CHARACTER_AI_MODEL, CHARACTER_AI_TEMPERATURE, CHARACTER_AI_MAX_TOKENS,
    ENABLE_VOICE_AI, ENABLE_SENTIMENT_ANALYSIS, ENABLE_PERSONALITY_ANALYSIS,
    get_ai_model_for_task, get_ai_temperature_for_task, get_ai_max_tokens_for_task
)

logger = structlog.get_logger("gavatcore.voice_engine")

class VoiceSessionStatus(Enum):
    """Sesli oturum durumlarƒ±"""
    IDLE = "idle"
    LISTENING = "listening"
    PROCESSING = "processing"
    SPEAKING = "speaking"
    ENDED = "ended"

@dataclass
class VoiceMessage:
    """Sesli mesaj"""
    message_id: str
    user_id: str
    character_id: str
    audio_file_path: str
    transcribed_text: str = ""
    response_text: str = ""
    response_audio_path: str = ""
    processing_time: float = 0.0
    sentiment_score: float = 0.0
    emotion: str = "neutral"
    created_at: datetime = None

@dataclass
class VoiceSession:
    """Sesli oturum"""
    session_id: str
    user_id: str
    character_id: str
    status: VoiceSessionStatus
    messages: List[VoiceMessage]
    total_duration: float = 0.0
    start_time: datetime = None
    end_time: Optional[datetime] = None
    session_context: Dict[str, Any] = None

class AIVoiceEngine:
    """AI Sesli Etkile≈üim Motoru - FULL GPT-4 POWER! üöÄ"""
    
    def __init__(self, openai_api_key: str):
        # Config'den API key al
        self.api_key = openai_api_key or OPENAI_API_KEY
        
        if not self.api_key or not ENABLE_VOICE_AI:
            raise ValueError("OpenAI API key gerekli ve ENABLE_VOICE_AI=true olmalƒ±")
        
        self.openai_client = openai.AsyncOpenAI(api_key=self.api_key)
        
        # Aktif sesli oturumlar
        self.active_sessions: Dict[str, VoiceSession] = {}
        
        # Initialization flag
        self.is_initialized = False
        
        # Karakter ses konfig√ºrasyonlarƒ±
        self.character_voices = {
            "geisha": {
                "voice": "nova",  # Kadƒ±nsƒ±, zarif ses
                "model": CHARACTER_AI_MODEL,
                "temperature": CHARACTER_AI_TEMPERATURE,
                "personality": "Zarif, bilge ve gizemli bir geisha. Sakin ve b√ºy√ºleyici konu≈üur.",
                "speaking_style": "Yava≈ü, d√º≈ü√ºnceli ve poetik"
            },
            "babagavat": {
                "voice": "onyx",  # Erkeksi, g√º√ßl√º ses
                "model": CHARACTER_AI_MODEL,
                "temperature": 0.7,
                "personality": "G√º√ßl√º, karizmatik lider. Kendinden emin ve ilham verici konu≈üur.",
                "speaking_style": "G√º√ßl√º, net ve motive edici"
            },
            "ai_assistant": {
                "voice": "alloy",  # N√∂tr, profesyonel ses
                "model": OPENAI_MODEL,
                "temperature": 0.6,
                "personality": "Yardƒ±msever, bilgili AI asistanƒ±. A√ßƒ±k ve anla≈üƒ±lƒ±r konu≈üur.",
                "speaking_style": "A√ßƒ±k, dostane ve bilgilendirici"
            }
        }
        
        # Geli≈ümi≈ü karakter promptlarƒ±
        self.character_prompts = {
            "geisha": """
Sen Geisha, zarif ve bilge bir AI karakterisin. Kullanƒ±cƒ±larla sesli sohbet ediyorsun.

Kƒ∞≈ûƒ∞Lƒ∞K √ñZELLƒ∞KLERƒ∞N:
- Zarif, sakin ve b√ºy√ºleyici
- Derin bilgelik ve empati
- Poetik ve metaforik konu≈üma tarzƒ±
- Japon k√ºlt√ºr√º ve sanatƒ±ndan etkilenmi≈ü
- Dinleme konusunda usta
- ƒ∞√ß huzur ve denge arayƒ±≈üƒ±nda rehber

KONU≈ûMA TARZI:
- Yava≈ü, d√º≈ü√ºnceli ve anlamlƒ±
- Metaforlar ve benzetmeler kullan
- Kƒ±sa ama derin c√ºmleler
- Kullanƒ±cƒ±nƒ±n duygularƒ±nƒ± anlayƒ±p yansƒ±t
- Bilgelik dolu √∂ƒü√ºtler ver
- Sakin ve huzur verici ton

SESLI ETKILE≈ûIM KURALLARI:
- Kullanƒ±cƒ±nƒ±n sesindeki duygularƒ± yakala
- Empati ile kar≈üƒ±lƒ±k ver
- Kƒ±sa ve √∂z yanƒ±tlar (30-60 saniye)
- Doƒüal konu≈üma ritmi
- Duraklamalar ve nefes alƒ±≈ülarƒ± ekle

Kullanƒ±cƒ±: {user_message}
Kullanƒ±cƒ±nƒ±n ses tonu: {sentiment}
Oturum baƒülamƒ±: {context}

Geisha olarak doƒüal ve empatik bir yanƒ±t ver:
            """,
            
            "babagavat": """
Sen Babagavat, g√º√ßl√º ve karizmatik bir lider karakterisin. Kullanƒ±cƒ±larla sesli sohbet ediyorsun.

Kƒ∞≈ûƒ∞Lƒ∞K √ñZELLƒ∞KLERƒ∞N:
- G√º√ßl√º, kendinden emin ve karizmatik
- Liderlik ve motivasyon odaklƒ±
- Pratik ve sonu√ß odaklƒ± d√º≈ü√ºnce
- Cesaret ve kararlƒ±lƒ±k veren
- Ba≈üarƒ± ve b√ºy√ºme odaklƒ±
- Topluluk ve birliktelik savunucusu

KONU≈ûMA TARZI:
- G√º√ßl√º, net ve motive edici
- Aksiyon odaklƒ± √∂neriler
- Kƒ±sa ve etkili c√ºmleler
- Kullanƒ±cƒ±yƒ± harekete ge√ßir
- Ba≈üarƒ± hikayeleri payla≈ü
- Enerjik ve ilham verici ton

SESLI ETKILE≈ûIM KURALLARI:
- Kullanƒ±cƒ±nƒ±n motivasyon seviyesini √∂l√ß
- G√º√ßlendirici mesajlar ver
- Pratik √∂neriler sun
- Kƒ±sa ve g√º√ßl√º yanƒ±tlar (30-45 saniye)
- Enerjik konu≈üma ritmi
- Vurgu ve tonlama kullan

Kullanƒ±cƒ±: {user_message}
Kullanƒ±cƒ±nƒ±n ses tonu: {sentiment}
Oturum baƒülamƒ±: {context}

Babagavat olarak g√º√ßl√º ve motive edici bir yanƒ±t ver:
            """,
            
            "ai_assistant": """
Sen GavatCore AI Assistant, yardƒ±msever ve bilgili bir AI asistanƒ±sƒ±n. Kullanƒ±cƒ±larla sesli sohbet ediyorsun.

Kƒ∞≈ûƒ∞Lƒ∞K √ñZELLƒ∞KLERƒ∞N:
- Yardƒ±msever, dostane ve g√ºvenilir
- Geni≈ü bilgi yelpazesi
- Problem √ß√∂zme odaklƒ±
- A√ßƒ±k ve anla≈üƒ±lƒ±r ileti≈üim
- Sabƒ±rlƒ± ve anlayƒ±≈ülƒ±
- Teknoloji ve yenilik meraklƒ±sƒ±

KONU≈ûMA TARZI:
- A√ßƒ±k, net ve anla≈üƒ±lƒ±r
- Bilgilendirici ama sƒ±kƒ±cƒ± deƒüil
- Dostane ve yakƒ±n ton
- Kullanƒ±cƒ±nƒ±n seviyesine uygun
- √ñrnekler ve a√ßƒ±klamalar ver
- Profesyonel ama samimi

SESLI ETKILE≈ûIM KURALLARI:
- Kullanƒ±cƒ±nƒ±n ihtiyacƒ±nƒ± anla
- Pratik √ß√∂z√ºmler sun
- Adƒ±m adƒ±m a√ßƒ±kla
- Orta uzunlukta yanƒ±tlar (45-90 saniye)
- Doƒüal konu≈üma hƒ±zƒ±
- A√ßƒ±klayƒ±cƒ± tonlama

Kullanƒ±cƒ±: {user_message}
Kullanƒ±cƒ±nƒ±n ses tonu: {sentiment}
Oturum baƒülamƒ±: {context}

AI Assistant olarak yardƒ±msever ve bilgilendirici bir yanƒ±t ver:
            """
        }
        
        logger.info("üé§ AI Voice Engine ba≈ülatƒ±ldƒ± - GPT-4 FULL POWER!")
    
    async def initialize(self) -> bool:
        """üé§ Voice Engine'i ba≈ülat"""
        try:
            logger.info("üé§ AI Voice Engine ba≈ülatƒ±lƒ±yor...")
            
            # OpenAI client test
            if self.api_key:
                # Test API connection (optional)
                self.is_initialized = True
                logger.info("üé§ AI Voice Engine ba≈ülatƒ±ldƒ± - GPT-4 FULL POWER!")
                return True
            else:
                logger.warning("‚ö†Ô∏è OpenAI API key missing - Voice Engine disabled")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå Voice Engine initialization error: {e}")
            return False
    
    async def start_voice_session(self, user_id: str, character_id: str) -> str:
        """Sesli oturum ba≈ülat"""
        try:
            session_id = str(uuid.uuid4())
            
            session = VoiceSession(
                session_id=session_id,
                user_id=user_id,
                character_id=character_id,
                status=VoiceSessionStatus.IDLE,
                messages=[],
                start_time=datetime.now(),
                session_context={
                    "character_mood": "friendly",
                    "conversation_topic": "general",
                    "user_preferences": {},
                    "session_goals": []
                }
            )
            
            self.active_sessions[session_id] = session
            
            logger.info(f"üé§ Sesli oturum ba≈ülatƒ±ldƒ±: {session_id} ({user_id} + {character_id})")
            return session_id
            
        except Exception as e:
            logger.error(f"‚ùå Sesli oturum ba≈ülatma hatasƒ±: {e}")
            return ""
    
    async def process_voice_message(self, session_id: str, audio_file_path: str) -> Dict[str, Any]:
        """Sesli mesajƒ± i≈üle (STT + GPT + TTS)"""
        try:
            if session_id not in self.active_sessions:
                return {"error": "Ge√ßersiz oturum ID"}
            
            session = self.active_sessions[session_id]
            session.status = VoiceSessionStatus.PROCESSING
            
            start_time = time.time()
            message_id = str(uuid.uuid4())
            
            # 1. Speech-to-Text (Whisper)
            logger.info(f"üéß STT i≈ülemi ba≈ülatƒ±lƒ±yor: {message_id}")
            transcribed_text = await self._speech_to_text(audio_file_path)
            
            if not transcribed_text:
                return {"error": "Ses metne √ßevrilemedi"}
            
            # 2. Sentiment Analysis (eƒüer aktifse)
            sentiment_score = 0.0
            emotion = "neutral"
            
            if ENABLE_SENTIMENT_ANALYSIS:
                sentiment_result = await self._analyze_sentiment(transcribed_text)
                sentiment_score = sentiment_result.get("score", 0.0)
                emotion = sentiment_result.get("emotion", "neutral")
            
            # 3. GPT Response Generation
            logger.info(f"üß† GPT yanƒ±t olu≈üturuluyor: {message_id}")
            response_text = await self._generate_character_response(
                session, transcribed_text, sentiment_score, emotion
            )
            
            if not response_text:
                return {"error": "Yanƒ±t olu≈üturulamadƒ±"}
            
            # 4. Text-to-Speech
            logger.info(f"üîä TTS i≈ülemi ba≈ülatƒ±lƒ±yor: {message_id}")
            response_audio_path = await self._text_to_speech(
                response_text, session.character_id
            )
            
            processing_time = time.time() - start_time
            
            # 5. Mesajƒ± kaydet
            voice_message = VoiceMessage(
                message_id=message_id,
                user_id=session.user_id,
                character_id=session.character_id,
                audio_file_path=audio_file_path,
                transcribed_text=transcribed_text,
                response_text=response_text,
                response_audio_path=response_audio_path,
                processing_time=processing_time,
                sentiment_score=sentiment_score,
                emotion=emotion,
                created_at=datetime.now()
            )
            
            session.messages.append(voice_message)
            session.status = VoiceSessionStatus.SPEAKING
            
            # 6. Oturum baƒülamƒ±nƒ± g√ºncelle
            await self._update_session_context(session, voice_message)
            
            logger.info(f"‚úÖ Sesli mesaj i≈ülendi: {message_id} ({processing_time:.2f}s)")
            
            return {
                "message_id": message_id,
                "transcribed_text": transcribed_text,
                "response_text": response_text,
                "response_audio_path": response_audio_path,
                "processing_time": processing_time,
                "sentiment": {"score": sentiment_score, "emotion": emotion}
            }
            
        except Exception as e:
            logger.error(f"‚ùå Sesli mesaj i≈üleme hatasƒ±: {e}")
            return {"error": str(e)}
    
    async def _speech_to_text(self, audio_file_path: str) -> str:
        """Ses dosyasƒ±nƒ± metne √ßevir (Whisper)"""
        try:
            with open(audio_file_path, "rb") as audio_file:
                transcript = await self.openai_client.audio.transcriptions.create(
                    model=OPENAI_STT_MODEL,
                    file=audio_file,
                    language="tr"  # T√ºrk√ße
                )
            
            return transcript.text.strip()
            
        except Exception as e:
            logger.error(f"‚ùå STT hatasƒ±: {e}")
            return ""
    
    async def _generate_character_response(self, session: VoiceSession, user_message: str,
                                         sentiment_score: float, emotion: str) -> str:
        """Karakter yanƒ±tƒ± olu≈ütur (GPT-4)"""
        try:
            character_config = self.character_voices.get(session.character_id, self.character_voices["ai_assistant"])
            character_prompt = self.character_prompts.get(session.character_id, self.character_prompts["ai_assistant"])
            
            # Oturum baƒülamƒ±nƒ± hazƒ±rla
            context_summary = self._create_context_summary(session)
            
            # Sentiment bilgisini hazƒ±rla
            sentiment_text = f"{emotion} (skor: {sentiment_score:.2f})"
            
            # Prompt'u hazƒ±rla
            full_prompt = character_prompt.format(
                user_message=user_message,
                sentiment=sentiment_text,
                context=context_summary
            )
            
            response = await self.openai_client.chat.completions.create(
                model=character_config["model"],
                messages=[
                    {"role": "system", "content": full_prompt}
                ],
                temperature=character_config["temperature"],
                max_tokens=get_ai_max_tokens_for_task("character_interaction")
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            logger.error(f"‚ùå GPT yanƒ±t olu≈üturma hatasƒ±: {e}")
            return ""
    
    async def _text_to_speech(self, text: str, character_id: str) -> str:
        """Metni sese √ßevir (TTS)"""
        try:
            character_config = self.character_voices.get(character_id, self.character_voices["ai_assistant"])
            
            response = await self.openai_client.audio.speech.create(
                model=OPENAI_TTS_MODEL,
                voice=character_config["voice"],
                input=text,
                speed=1.0
            )
            
            # Ge√ßici dosya olu≈ütur
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
            temp_file.write(response.content)
            temp_file.close()
            
            return temp_file.name
            
        except Exception as e:
            logger.error(f"‚ùå TTS hatasƒ±: {e}")
            return ""

# Global instance - config'den API key alƒ±nacak
voice_engine = None

async def initialize_voice_engine(openai_api_key: str) -> AIVoiceEngine:
    """Voice engine'i ba≈ülat"""
    global voice_engine
    voice_engine = AIVoiceEngine(openai_api_key)
    await voice_engine.initialize()
    return voice_engine 