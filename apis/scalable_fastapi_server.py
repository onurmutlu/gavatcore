from infrastructure.config.logger import get_logger

#!/usr/bin/env python3
"""
ðŸš€ GAVATCore Scalable FastAPI Server
Enterprise-grade asynchronous API with load balancing and advanced optimizations

Features:
- Async request processing
- Load balancing integration
- Circuit breaker protection
- Rate limiting
- Connection pooling
- Real-time metrics
- Auto-scaling capabilities
- Health monitoring
"""

import asyncio
import time
import json
import logging
import uuid
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta
from contextlib import asynccontextmanager

from fastapi import FastAPI, HTTPException, Depends, BackgroundTasks, Request, Response
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.gzip import GZipMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field
import uvicorn
import structlog

# Import our advanced framework
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    from core.advanced_async_framework import (
        get_async_framework,
        initialize_framework,
        shutdown_framework,
        ServiceEndpoint,
        LoadBalancingStrategy,
        async_protected
    )
except ImportError:
    # Fallback for standalone operation
    print("âš ï¸ Advanced async framework not available, using basic mode")
    
    class MockFramework:
        async def start(self): pass
        async def stop(self): pass
        def get_system_status(self): return {}
    
    def get_async_framework():
        return MockFramework()
    
    async def initialize_framework():
        return MockFramework()
    
    async def shutdown_framework():
        pass
    
    def async_protected(*args, **kwargs):
        def decorator(func):
            return func
        return decorator

# Configure structured logging

logger = structlog.get_logger("gavatcore.scalable_api")

# Pydantic Models
class TaskRequest(BaseModel):
    task_type: str = Field(..., description="Type of task to execute")
    parameters: Dict[str, Any] = Field(default_factory=dict, description="Task parameters")
    priority: int = Field(default=5, ge=1, le=10, description="Task priority (1=highest)")
    async_mode: bool = Field(default=True, description="Execute task asynchronously")

class TaskResponse(BaseModel):
    task_id: str
    status: str
    message: str
    estimated_completion: Optional[datetime] = None

class SystemMetrics(BaseModel):
    timestamp: datetime
    requests_per_second: float
    average_response_time: float
    active_connections: int
    queue_size: int
    cpu_usage: float
    memory_usage: float
    error_rate: float
    cache_hit_rate: float

class HealthStatus(BaseModel):
    status: str
    timestamp: datetime
    version: str = "6.0.0"
    uptime_seconds: float
    system_metrics: SystemMetrics
    components: Dict[str, str]

class EndpointInfo(BaseModel):
    id: str
    host: str
    port: int
    healthy: bool
    current_connections: int
    response_time: float
    load_score: float

# Global variables
app_start_time = time.time()
request_metrics = {
    'total_requests': 0,
    'total_response_time': 0.0,
    'error_count': 0,
    'success_count': 0
}

# Async context manager for application lifecycle
@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifecycle management."""
    logger.info("ðŸš€ Starting GAVATCore Scalable API Server...")
    
    # Initialize async framework
    try:
        framework = await initialize_framework()
        
        # Add sample service endpoints for load balancing
        sample_endpoints = [
            ServiceEndpoint(
                id="gavatcore-1",
                host="localhost",
                port=5050,
                weight=2,
                max_connections=100
            ),
            ServiceEndpoint(
                id="admin-dashboard-1", 
                host="localhost",
                port=5055,
                weight=1,
                max_connections=50
            )
        ]
        
        for endpoint in sample_endpoints:
            framework.load_balancer.add_endpoint(endpoint)
        
        app.state.framework = framework
        logger.info("âœ… Advanced async framework initialized")
        
    except Exception as e:
        logger.error("âŒ Framework initialization failed", error=str(e))
        raise e
    
    yield
    
    # Cleanup
    logger.info("ðŸ”„ Shutting down GAVATCore Scalable API Server...")
    try:
        await shutdown_framework()
        logger.info("âœ… Framework shutdown complete")
    except Exception as e:
        logger.error("âŒ Framework shutdown error", error=str(e))

# FastAPI application
app = FastAPI(
    title="GAVATCore Scalable API",
    description="Enterprise-grade asynchronous API with load balancing",
    version="6.0.0",
    lifespan=lifespan
)

# Middleware configuration
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

app.add_middleware(GZipMiddleware, minimum_size=1000)

# Request timing middleware
@app.middleware("http")
async def timing_middleware(request: Request, call_next):
    """Middleware to track request timing and metrics."""
    start_time = time.time()
    
    try:
        response = await call_next(request)
        process_time = time.time() - start_time
        
        # Update metrics
        request_metrics['total_requests'] += 1
        request_metrics['total_response_time'] += process_time
        request_metrics['success_count'] += 1
        
        # Add timing header
        response.headers["X-Process-Time"] = str(process_time)
        response.headers["X-Request-ID"] = str(uuid.uuid4())
        
        logger.debug("ðŸ“Š Request processed", 
                    method=request.method,
                    path=request.url.path,
                    duration=process_time,
                    status_code=response.status_code)
        
        return response
        
    except Exception as e:
        process_time = time.time() - start_time
        request_metrics['total_requests'] += 1
        request_metrics['error_count'] += 1
        
        logger.error("âŒ Request failed",
                    method=request.method,
                    path=request.url.path,
                    duration=process_time,
                    error=str(e))
        
        raise e

# Dependency injection
async def get_framework():
    """Get async framework dependency."""
    return getattr(app.state, 'framework', None)

# API Endpoints

@app.get("/", response_model=Dict[str, Any])
async def root():
    """API root endpoint."""
    return {
        "service": "GAVATCore Scalable API",
        "version": "6.0.0",
        "status": "operational",
        "timestamp": datetime.now().isoformat(),
        "features": [
            "Asynchronous Processing",
            "Load Balancing",
            "Circuit Breaker Protection", 
            "Rate Limiting",
            "Connection Pooling",
            "Real-time Metrics",
            "Auto-scaling"
        ],
        "endpoints": {
            "health": "/health",
            "metrics": "/metrics", 
            "tasks": "/api/v1/tasks",
            "load-balancer": "/api/v1/load-balancer",
            "system": "/api/v1/system"
        }
    }

@app.get("/health", response_model=HealthStatus)
async def health_check(framework = Depends(get_framework)):
    """Comprehensive health check endpoint."""
    uptime = time.time() - app_start_time
    
    # Calculate metrics
    total_requests = request_metrics['total_requests']
    avg_response_time = (
        request_metrics['total_response_time'] / max(total_requests, 1)
    )
    error_rate = (
        request_metrics['error_count'] / max(total_requests, 1) * 100
    )
    
    # System metrics
    import psutil
    cpu_usage = psutil.cpu_percent()
    memory_info = psutil.virtual_memory()
    
    system_metrics = SystemMetrics(
        timestamp=datetime.now(),
        requests_per_second=total_requests / max(uptime, 1),
        average_response_time=avg_response_time,
        active_connections=0,  # Would be populated from framework
        queue_size=0,  # Would be populated from framework
        cpu_usage=cpu_usage,
        memory_usage=memory_info.percent,
        error_rate=error_rate,
        cache_hit_rate=85.0  # Sample cache hit rate
    )
    
    # Component status
    components = {
        "api_server": "healthy",
        "async_framework": "healthy" if framework else "unavailable",
        "load_balancer": "healthy" if framework else "unavailable",
        "task_processor": "healthy" if framework else "unavailable",
        "database": "healthy",
        "cache": "healthy"
    }
    
    overall_status = "healthy" if all(
        status == "healthy" for status in components.values()
    ) else "degraded"
    
    return HealthStatus(
        status=overall_status,
        timestamp=datetime.now(),
        uptime_seconds=uptime,
        system_metrics=system_metrics,
        components=components
    )

@app.get("/metrics", response_model=Dict[str, Any])
@async_protected("metrics_service", rate_limit_tokens=1)
async def get_metrics(framework = Depends(get_framework)):
    """Get detailed system metrics."""
    uptime = time.time() - app_start_time
    
    base_metrics = {
        "uptime_seconds": uptime,
        "request_metrics": request_metrics.copy(),
        "timestamp": datetime.now().isoformat()
    }
    
    if framework:
        framework_status = framework.get_system_status()
        base_metrics.update(framework_status)
    
    return base_metrics

@app.post("/api/v1/tasks", response_model=TaskResponse)
@async_protected("task_service", rate_limit_tokens=2)
async def submit_task(
    task_request: TaskRequest,
    background_tasks: BackgroundTasks,
    framework = Depends(get_framework)
):
    """Submit async task for processing."""
    task_id = str(uuid.uuid4())
    
    logger.info("ðŸ“ Task submitted",
               task_id=task_id,
               task_type=task_request.task_type,
               priority=task_request.priority)
    
    if framework and task_request.async_mode:
        # Submit to async framework
        try:
            submitted_task_id = await framework.task_processor.submit_task(
                _process_task,
                task_request.task_type,
                task_request.parameters,
                priority=task_request.priority,
                task_id=task_id
            )
            
            return TaskResponse(
                task_id=submitted_task_id,
                status="submitted",
                message="Task submitted for async processing",
                estimated_completion=datetime.now() + timedelta(seconds=30)
            )
            
        except Exception as e:
            logger.error("âŒ Task submission failed", error=str(e))
            raise HTTPException(status_code=500, detail=f"Task submission failed: {str(e)}")
    else:
        # Process synchronously as background task
        background_tasks.add_task(
            _process_task,
            task_request.task_type,
            task_request.parameters
        )
        
        return TaskResponse(
            task_id=task_id,
            status="processing",
            message="Task processing started",
            estimated_completion=datetime.now() + timedelta(seconds=10)
        )

@app.get("/api/v1/tasks/{task_id}")
@async_protected("task_service", rate_limit_tokens=1)
async def get_task_result(task_id: str, framework = Depends(get_framework)):
    """Get task result by ID."""
    if not framework:
        raise HTTPException(status_code=503, detail="Task framework unavailable")
    
    result = framework.task_processor.get_result_nowait(task_id)
    
    if not result:
        raise HTTPException(status_code=404, detail="Task not found")
    
    return {
        "task_id": result.task_id,
        "status": result.status,
        "result": result.result,
        "error": result.error,
        "execution_time": result.execution_time,
        "start_time": result.start_time.isoformat() if result.start_time else None,
        "end_time": result.end_time.isoformat() if result.end_time else None
    }

@app.get("/api/v1/load-balancer/endpoints", response_model=List[EndpointInfo])
@async_protected("admin_service", rate_limit_tokens=1)
async def get_endpoints(framework = Depends(get_framework)):
    """Get load balancer endpoints."""
    if not framework:
        raise HTTPException(status_code=503, detail="Load balancer unavailable")
    
    endpoints = []
    for ep in framework.load_balancer.endpoints:
        endpoints.append(EndpointInfo(
            id=ep.id,
            host=ep.host,
            port=ep.port,
            healthy=ep.healthy,
            current_connections=ep.current_connections,
            response_time=ep.response_time,
            load_score=ep.load_score
        ))
    
    return endpoints

@app.post("/api/v1/load-balancer/endpoints")
@async_protected("admin_service", rate_limit_tokens=1)
async def add_endpoint(
    endpoint_data: Dict[str, Any],
    framework = Depends(get_framework)
):
    """Add new endpoint to load balancer."""
    if not framework:
        raise HTTPException(status_code=503, detail="Load balancer unavailable")
    
    try:
        endpoint = ServiceEndpoint(
            id=endpoint_data['id'],
            host=endpoint_data['host'],
            port=endpoint_data['port'],
            weight=endpoint_data.get('weight', 1),
            max_connections=endpoint_data.get('max_connections', 100)
        )
        
        framework.load_balancer.add_endpoint(endpoint)
        
        return {"message": "Endpoint added successfully", "endpoint_id": endpoint.id}
        
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Failed to add endpoint: {str(e)}")

@app.delete("/api/v1/load-balancer/endpoints/{endpoint_id}")
@async_protected("admin_service", rate_limit_tokens=1)
async def remove_endpoint(endpoint_id: str, framework = Depends(get_framework)):
    """Remove endpoint from load balancer."""
    if not framework:
        raise HTTPException(status_code=503, detail="Load balancer unavailable")
    
    framework.load_balancer.remove_endpoint(endpoint_id)
    return {"message": "Endpoint removed successfully", "endpoint_id": endpoint_id}

@app.get("/api/v1/system/status")
@async_protected("system_service", rate_limit_tokens=1)
async def system_status(framework = Depends(get_framework)):
    """Get comprehensive system status."""
    status_data = {
        "timestamp": datetime.now().isoformat(),
        "uptime_seconds": time.time() - app_start_time,
        "api_server": {
            "status": "healthy",
            "total_requests": request_metrics['total_requests'],
            "success_rate": (
                request_metrics['success_count'] / 
                max(request_metrics['total_requests'], 1) * 100
            ),
            "average_response_time": (
                request_metrics['total_response_time'] /
                max(request_metrics['total_requests'], 1)
            )
        }
    }
    
    if framework:
        status_data["framework"] = framework.get_system_status()
    
    return status_data

@app.post("/api/v1/system/stress-test")
@async_protected("admin_service", rate_limit_tokens=5)
async def stress_test(
    concurrent_requests: int = 10,
    duration_seconds: int = 30,
    framework = Depends(get_framework)
):
    """Run stress test on the system."""
    if concurrent_requests > 100:
        raise HTTPException(status_code=400, detail="Too many concurrent requests")
    
    if duration_seconds > 300:
        raise HTTPException(status_code=400, detail="Test duration too long")
    
    stress_test_id = str(uuid.uuid4())
    
    # Submit stress test as async task
    if framework:
        await framework.task_processor.submit_task(
            _run_stress_test,
            concurrent_requests,
            duration_seconds,
            task_id=stress_test_id
        )
    
    return {
        "stress_test_id": stress_test_id,
        "status": "started",
        "concurrent_requests": concurrent_requests,
        "duration_seconds": duration_seconds,
        "message": "Stress test started"
    }

# Task processing functions
async def _process_task(task_type: str, parameters: Dict[str, Any]) -> Dict[str, Any]:
    """Process async task."""
    logger.info("âš¡ Processing task", task_type=task_type)
    
    # Simulate task processing
    if task_type == "data_analysis":
        await asyncio.sleep(2)  # Simulate analysis
        return {"result": "Analysis completed", "data_points": 1000}
    
    elif task_type == "cache_warmup":
        await asyncio.sleep(1)  # Simulate cache warming
        return {"result": "Cache warmed", "entries": 500}
    
    elif task_type == "batch_processing":
        batch_size = parameters.get("batch_size", 100)
        await asyncio.sleep(batch_size * 0.01)  # Simulate batch processing
        return {"result": "Batch processed", "processed_items": batch_size}
    
    else:
        await asyncio.sleep(0.5)  # Default processing
        return {"result": f"Task {task_type} completed", "parameters": parameters}

async def _run_stress_test(concurrent_requests: int, duration_seconds: int) -> Dict[str, Any]:
    """Run internal stress test."""
    logger.info("ðŸ”¥ Starting stress test", 
               concurrent_requests=concurrent_requests,
               duration=duration_seconds)
    
    start_time = time.time()
    success_count = 0
    error_count = 0
    response_times = []
    
    async def make_request():
        nonlocal success_count, error_count, response_times
        try:
            request_start = time.time()
            # Simulate request processing
            await asyncio.sleep(0.1)
            response_time = time.time() - request_start
            response_times.append(response_time)
            success_count += 1
        except Exception:
            error_count += 1
    
    # Run stress test
    while time.time() - start_time < duration_seconds:
        tasks = [make_request() for _ in range(concurrent_requests)]
        await asyncio.gather(*tasks, return_exceptions=True)
        await asyncio.sleep(0.1)
    
    total_requests = success_count + error_count
    avg_response_time = sum(response_times) / max(len(response_times), 1)
    
    result = {
        "duration_seconds": time.time() - start_time,
        "total_requests": total_requests,
        "successful_requests": success_count,
        "failed_requests": error_count,
        "success_rate": (success_count / max(total_requests, 1)) * 100,
        "average_response_time": avg_response_time,
        "requests_per_second": total_requests / (time.time() - start_time)
    }
    
    logger.info("ðŸ”¥ Stress test completed", **result)
    return result

# Error handlers
@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    """Handle HTTP exceptions."""
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error": exc.detail,
            "status_code": exc.status_code,
            "timestamp": datetime.now().isoformat(),
            "path": request.url.path
        }
    )

@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    """Handle general exceptions."""
    logger.error("ðŸ’¥ Unhandled exception", 
                error=str(exc),
                path=request.url.path)
    
    return JSONResponse(
        status_code=500,
        content={
            "error": "Internal server error",
            "message": "An unexpected error occurred",
            "timestamp": datetime.now().isoformat(),
            "path": request.url.path
        }
    )

def main():
    """Run the scalable FastAPI server."""
    print("ðŸš€ Starting GAVATCore Scalable FastAPI Server...")
    print("="*60)
    print("ðŸ”§ Features:")
    print("   â€¢ Asynchronous request processing")
    print("   â€¢ Load balancing integration")
    print("   â€¢ Circuit breaker protection")
    print("   â€¢ Rate limiting")
    print("   â€¢ Connection pooling")
    print("   â€¢ Real-time metrics")
    print("   â€¢ Auto-scaling support")
    print("="*60)
    print("ðŸŒ Server starting on http://localhost:6000")
    print("ðŸ“Š Health check: http://localhost:6000/health")
    print("ðŸ“ˆ Metrics: http://localhost:6000/metrics")
    print("="*60)
    
    uvicorn.run(
        "scalable_fastapi_server:app",
        host="0.0.0.0",
        port=6000,
        reload=False,
        workers=1,  # Use 1 worker for async operations
        loop="asyncio",
        log_level="info",
        access_log=True
    )

if __name__ == "__main__":
    main() 