from infrastructure.config.logger import get_logger

#!/usr/bin/env python3
"""
ğŸ” GAVATCore Performance Profiler & Bottleneck Analyzer
=====================================================

DetaylÄ± cProfile analizi ve performans optimizasyonu.
Sistem bottleneck'lerini tespit eder ve optimize edilmiÅŸ Ã§Ã¶zÃ¼mler sunar.

@version: 1.0.0
@created: 2025-01-30
"""

import cProfile
import pstats
import io
import time
import asyncio
import json
import sys
import tracemalloc
from datetime import datetime
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass, field
from pathlib import Path
import structlog

# Performance monitoring imports
try:
    import psutil
    import memory_profiler
    PROFILING_AVAILABLE = True
except ImportError:
    PROFILING_AVAILABLE = False

logger = structlog.get_logger("performance_profiler")

@dataclass
class BottleneckReport:
    """Bottleneck analysis report"""
    function_name: str
    total_time: float
    cumulative_time: float
    call_count: int
    per_call_time: float
    percentage_of_total: float
    memory_usage_mb: float = 0.0
    optimization_priority: str = "medium"
    
    @property
    def is_critical(self) -> bool:
        return (self.percentage_of_total > 10.0 or 
                self.per_call_time > 0.1 or 
                self.memory_usage_mb > 50.0)

@dataclass
class ProfilingSession:
    """Profiling session results"""
    session_name: str
    start_time: datetime = field(default_factory=datetime.now)
    end_time: Optional[datetime] = None
    bottlenecks: List[BottleneckReport] = field(default_factory=list)
    total_execution_time: float = 0.0
    memory_usage_peak: float = 0.0
    optimization_recommendations: List[str] = field(default_factory=list)

class GAVATCorePerformanceProfiler:
    """
    ğŸ” Comprehensive Performance Profiler
    
    DetaylÄ± cProfile analizi ile bottleneck tespiti ve optimizasyon Ã¶nerileri.
    """
    
    def __init__(self):
        self.profiling_sessions: List[ProfilingSession] = []
        self.profiler = cProfile.Profile()
        self.memory_tracer_active = False
        
        logger.info("ğŸ” GAVATCore Performance Profiler baÅŸlatÄ±ldÄ±")
    
    def start_memory_tracking(self):
        """Memory tracking baÅŸlat"""
        if not self.memory_tracer_active:
            tracemalloc.start()
            self.memory_tracer_active = True
            logger.info("ğŸ“Š Memory tracking baÅŸlatÄ±ldÄ±")
    
    def stop_memory_tracking(self) -> Dict[str, float]:
        """Memory tracking durdur ve sonuÃ§larÄ± dÃ¶ndÃ¼r"""
        if self.memory_tracer_active:
            current, peak = tracemalloc.get_traced_memory()
            tracemalloc.stop()
            self.memory_tracer_active = False
            
            return {
                "current_memory_mb": current / (1024 * 1024),
                "peak_memory_mb": peak / (1024 * 1024)
            }
        return {"current_memory_mb": 0.0, "peak_memory_mb": 0.0}
    
    def profile_function(self, func: Callable, *args, **kwargs) -> Any:
        """Bir fonksiyonu profile et"""
        self.start_memory_tracking()
        
        # cProfile ile profiling
        self.profiler.enable()
        start_time = time.time()
        
        try:
            result = func(*args, **kwargs)
        except Exception as e:
            logger.error(f"Profiling sÄ±rasÄ±nda hata: {e}")
            result = None
        finally:
            end_time = time.time()
            self.profiler.disable()
        
        # Memory tracking sonuÃ§larÄ±
        memory_stats = self.stop_memory_tracking()
        
        # Profiling sonuÃ§larÄ±nÄ± analiz et
        execution_time = end_time - start_time
        logger.info(f"Fonksiyon profiling tamamlandÄ±: {execution_time:.4f}s")
        
        return result
    
    async def profile_async_function(self, func: Callable, *args, **kwargs) -> Any:
        """Async bir fonksiyonu profile et"""
        self.start_memory_tracking()
        
        # cProfile async desteÄŸi iÃ§in wrapper
        def async_wrapper():
            return asyncio.run(func(*args, **kwargs))
        
        self.profiler.enable()
        start_time = time.time()
        
        try:
            result = await func(*args, **kwargs)
        except Exception as e:
            logger.error(f"Async profiling sÄ±rasÄ±nda hata: {e}")
            result = None
        finally:
            end_time = time.time()
            self.profiler.disable()
        
        memory_stats = self.stop_memory_tracking()
        execution_time = end_time - start_time
        
        logger.info(f"Async fonksiyon profiling tamamlandÄ±: {execution_time:.4f}s")
        return result
    
    def analyze_bottlenecks(self, min_percentage: float = 1.0) -> List[BottleneckReport]:
        """cProfile sonuÃ§larÄ±ndan bottleneck'leri analiz et"""
        
        # cProfile sonuÃ§larÄ±nÄ± string buffer'a al
        s = io.StringIO()
        stats = pstats.Stats(self.profiler, stream=s)
        stats.sort_stats('cumulative')
        stats.print_stats()
        
        # SonuÃ§larÄ± parse et
        profile_output = s.getvalue()
        bottlenecks = []
        
        # Profile output'unu satÄ±r satÄ±r analiz et
        lines = profile_output.split('\n')
        data_started = False
        total_time = 0.0
        
        for line in lines:
            if 'function calls' in line and 'CPU seconds' in line:
                # Total time bilgisini Ã§Ä±kar
                try:
                    total_time = float(line.split('CPU seconds')[0].split()[-1])
                except:
                    total_time = 1.0
                continue
            
            if line.strip().startswith('ncalls'):
                data_started = True
                continue
                
            if data_started and line.strip():
                try:
                    # Parse function data
                    parts = line.strip().split()
                    if len(parts) >= 6:
                        ncalls = parts[0]
                        tottime = float(parts[1])
                        percall_tottime = float(parts[2]) if parts[2] != '0.000' else 0.0
                        cumtime = float(parts[3])
                        percall_cumtime = float(parts[4]) if parts[4] != '0.000' else 0.0
                        filename_function = ' '.join(parts[5:])
                        
                        # Call count parse et
                        call_count = int(ncalls.split('/')[0])
                        
                        # Percentage hesapla
                        percentage = (cumtime / total_time * 100) if total_time > 0 else 0
                        
                        if percentage >= min_percentage:
                            # Optimization priority belirleme
                            if percentage > 20:
                                priority = "critical"
                            elif percentage > 10:
                                priority = "high"
                            elif percentage > 5:
                                priority = "medium"
                            else:
                                priority = "low"
                            
                            bottleneck = BottleneckReport(
                                function_name=filename_function,
                                total_time=tottime,
                                cumulative_time=cumtime,
                                call_count=call_count,
                                per_call_time=percall_cumtime,
                                percentage_of_total=percentage,
                                optimization_priority=priority
                            )
                            
                            bottlenecks.append(bottleneck)
                            
                except (ValueError, IndexError) as e:
                    continue
        
        # Bottleneck'leri percentage'a gÃ¶re sÄ±rala
        bottlenecks.sort(key=lambda x: x.percentage_of_total, reverse=True)
        
        logger.info(f"ğŸ” {len(bottlenecks)} bottleneck tespit edildi")
        return bottlenecks
    
    def generate_optimization_recommendations(self, bottlenecks: List[BottleneckReport]) -> List[str]:
        """Bottleneck'lere dayalÄ± optimizasyon Ã¶nerileri oluÅŸtur"""
        recommendations = []
        
        critical_bottlenecks = [b for b in bottlenecks if b.is_critical]
        
        if critical_bottlenecks:
            recommendations.append("ğŸš¨ Kritik performans sorunlarÄ± tespit edildi:")
            
            for bottleneck in critical_bottlenecks[:5]:  # Top 5
                if "behavioral" in bottleneck.function_name.lower():
                    recommendations.append(
                        f"â€¢ Behavioral analysis optimize et: {bottleneck.function_name} "
                        f"({bottleneck.percentage_of_total:.1f}% CPU)"
                    )
                elif "cache" in bottleneck.function_name.lower():
                    recommendations.append(
                        f"â€¢ Cache operations optimize et: {bottleneck.function_name} "
                        f"({bottleneck.percentage_of_total:.1f}% CPU)"
                    )
                elif "database" in bottleneck.function_name.lower() or "sql" in bottleneck.function_name.lower():
                    recommendations.append(
                        f"â€¢ Database queries optimize et: {bottleneck.function_name} "
                        f"({bottleneck.percentage_of_total:.1f}% CPU)"
                    )
                elif "json" in bottleneck.function_name.lower() or "pickle" in bottleneck.function_name.lower():
                    recommendations.append(
                        f"â€¢ Serialization optimize et: {bottleneck.function_name} "
                        f"({bottleneck.percentage_of_total:.1f}% CPU)"
                    )
                else:
                    recommendations.append(
                        f"â€¢ Optimize: {bottleneck.function_name} "
                        f"({bottleneck.percentage_of_total:.1f}% CPU)"
                    )
        
        # Genel optimizasyon Ã¶nerileri
        high_call_count_funcs = [b for b in bottlenecks if b.call_count > 1000]
        if high_call_count_funcs:
            recommendations.append("ğŸ”„ YÃ¼ksek call count optimizasyonlarÄ±:")
            recommendations.append("â€¢ Function call overhead'Ä± azalt")
            recommendations.append("â€¢ Caching/memoization kullan")
            recommendations.append("â€¢ Batch processing implementasyonu")
        
        slow_per_call_funcs = [b for b in bottlenecks if b.per_call_time > 0.01]
        if slow_per_call_funcs:
            recommendations.append("â±ï¸ YavaÅŸ fonksiyon optimizasyonlarÄ±:")
            recommendations.append("â€¢ Algoritma complexity azalt")
            recommendations.append("â€¢ I/O operations optimize et")
            recommendations.append("â€¢ Parallel processing kullan")
        
        return recommendations
    
    def save_profiling_report(self, session: ProfilingSession, filename: Optional[str] = None) -> str:
        """Profiling raporunu kaydet"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"profiling_report_{timestamp}.json"
        
        report_data = {
            "session_name": session.session_name,
            "timestamp": session.start_time.isoformat(),
            "execution_time_seconds": session.total_execution_time,
            "memory_peak_mb": session.memory_usage_peak,
            "bottlenecks_count": len(session.bottlenecks),
            "critical_bottlenecks": len([b for b in session.bottlenecks if b.is_critical]),
            "bottlenecks": [
                {
                    "function": b.function_name,
                    "total_time": b.total_time,
                    "cumulative_time": b.cumulative_time,
                    "call_count": b.call_count,
                    "per_call_time": b.per_call_time,
                    "cpu_percentage": b.percentage_of_total,
                    "priority": b.optimization_priority
                }
                for b in session.bottlenecks[:20]  # Top 20
            ],
            "optimization_recommendations": session.optimization_recommendations
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ“„ Profiling raporu kaydedildi: {filename}")
        return filename

# Test scenarios iÃ§in performance test fonksiyonlarÄ±
def simulate_behavioral_analysis():
    """Behavioral analysis simulation for profiling"""
    import random
    import json
    
    # Simulate heavy computation
    users_data = []
    for i in range(100):
        user_data = {
            "user_id": i,
            "messages": [f"Message {j} from user {i}" for j in range(10)],
            "personality_traits": {
                "openness": random.random(),
                "conscientiousness": random.random(),
                "extraversion": random.random(),
                "agreeableness": random.random(),
                "neuroticism": random.random()
            }
        }
        
        # Simulate complex calculations
        for trait, value in user_data["personality_traits"].items():
            # Complex mathematical operations
            result = 0
            for _ in range(1000):
                result += value * random.random() ** 2
        
        # JSON serialization/deserialization
        json_str = json.dumps(user_data)
        parsed_data = json.loads(json_str)
        
        users_data.append(parsed_data)
    
    return users_data

def simulate_cache_operations():
    """Cache operations simulation for profiling"""
    cache_data = {}
    
    # Simulate cache set operations
    for i in range(500):
        key = f"cache_key_{i}"
        value = {
            "data": f"cached_value_{i}",
            "timestamp": time.time(),
            "metadata": {"priority": i % 10}
        }
        
        # Simulate hash calculation
        import hashlib
        key_hash = hashlib.md5(key.encode()).hexdigest()
        
        # Simulate compression
        import json
        json_str = json.dumps(value)
        
        cache_data[key_hash] = json_str
    
    # Simulate cache get operations
    hits = 0
    for i in range(200):
        key = f"cache_key_{i % 100}"
        key_hash = hashlib.md5(key.encode()).hexdigest()
        
        if key_hash in cache_data:
            data = json.loads(cache_data[key_hash])
            hits += 1
    
    return hits

def simulate_database_operations():
    """Database operations simulation for profiling"""
    import sqlite3
    import tempfile
    import os
    
    # Temporary database
    temp_db = tempfile.NamedTemporaryFile(suffix='.db', delete=False)
    temp_db.close()
    
    try:
        conn = sqlite3.connect(temp_db.name)
        cursor = conn.cursor()
        
        # Create table
        cursor.execute('''
            CREATE TABLE users (
                id INTEGER PRIMARY KEY,
                name TEXT,
                data TEXT
            )
        ''')
        
        # Insert operations
        for i in range(1000):
            cursor.execute(
                "INSERT INTO users (name, data) VALUES (?, ?)",
                (f"User_{i}", f"Data_{i}" * 100)
            )
        
        conn.commit()
        
        # Select operations
        for i in range(100):
            cursor.execute("SELECT * FROM users WHERE id = ?", (i,))
            result = cursor.fetchone()
        
        # Complex query
        cursor.execute("""
            SELECT name, COUNT(*) as count 
            FROM users 
            WHERE name LIKE 'User_%' 
            GROUP BY name 
            ORDER BY count DESC 
            LIMIT 10
        """)
        results = cursor.fetchall()
        
        conn.close()
        return len(results)
        
    finally:
        os.unlink(temp_db.name)

async def main():
    """Ana profiling test fonksiyonu"""
    profiler = GAVATCorePerformanceProfiler()
    
    print("\nğŸ” GAVATCore Performance Profiling BaÅŸlatÄ±lÄ±yor...")
    print("=" * 60)
    
    # Test scenarios
    test_scenarios = [
        ("Behavioral Analysis", simulate_behavioral_analysis),
        ("Cache Operations", simulate_cache_operations),
        ("Database Operations", simulate_database_operations)
    ]
    
    for scenario_name, test_func in test_scenarios:
        print(f"\nğŸ“Š Profiling: {scenario_name}")
        print("-" * 40)
        
        session = ProfilingSession(session_name=scenario_name)
        
        # Profiling yap
        start_time = time.time()
        result = profiler.profile_function(test_func)
        end_time = time.time()
        
        session.total_execution_time = end_time - start_time
        session.end_time = datetime.now()
        
        # Bottleneck analizi
        bottlenecks = profiler.analyze_bottlenecks(min_percentage=0.5)
        session.bottlenecks = bottlenecks
        
        # Optimization recommendations
        recommendations = profiler.generate_optimization_recommendations(bottlenecks)
        session.optimization_recommendations = recommendations
        
        # SonuÃ§larÄ± gÃ¶ster
        print(f"âœ… Execution Time: {session.total_execution_time:.4f}s")
        print(f"ğŸ” Bottlenecks Found: {len(bottlenecks)}")
        
        if bottlenecks:
            print(f"\nğŸš¨ Top 5 Bottlenecks:")
            for i, bottleneck in enumerate(bottlenecks[:5], 1):
                print(f"   {i}. {bottleneck.function_name}")
                print(f"      CPU: {bottleneck.percentage_of_total:.2f}% | "
                      f"Calls: {bottleneck.call_count} | "
                      f"Per Call: {bottleneck.per_call_time:.6f}s")
        
        if recommendations:
            print(f"\nğŸ’¡ Optimization Recommendations:")
            for rec in recommendations[:3]:
                print(f"   â€¢ {rec}")
        
        # Raporu kaydet
        report_file = profiler.save_profiling_report(session)
        profiler.profiling_sessions.append(session)
        
        # Profiler'Ä± reset et
        profiler.profiler = cProfile.Profile()
    
    # Overall summary
    total_bottlenecks = sum(len(s.bottlenecks) for s in profiler.profiling_sessions)
    critical_bottlenecks = sum(
        len([b for b in s.bottlenecks if b.is_critical]) 
        for s in profiler.profiling_sessions
    )
    
    print(f"\nğŸ¯ PROFILING SUMMARY")
    print("=" * 30)
    print(f"Total Scenarios: {len(profiler.profiling_sessions)}")
    print(f"Total Bottlenecks: {total_bottlenecks}")
    print(f"Critical Issues: {critical_bottlenecks}")
    
    if critical_bottlenecks > 0:
        print(f"\nâš ï¸ {critical_bottlenecks} kritik performans sorunu tespit edildi!")
        print("Optimizasyon Ã¶nerileri iÃ§in raporlarÄ± inceleyin.")
    else:
        print(f"\nâœ… Kritik performans sorunu tespit edilmedi.")
    
    print(f"\nğŸ“„ DetaylÄ± raporlar kaydedildi.")

if __name__ == "__main__":
    asyncio.run(main())